---
title: "p8105_hw6_ay2543"
author: "Amy Yeung"
output: github_document
---


```{r include=F}
library(tidyverse)
library(modelr)
library(mgcv)
```

# Problem 1

To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 


# Problem 2

Loaded homicide data and cleaned it:
* created a `city_state` variable
* added a variable to binarize whether the homicide has been solved or not
* substituded unknown `victim_sex` entries as NA
* converted `victim_age` into a numeric variable
* removed Dallas, TX, Phoenix, AZ, Kansas City, MO, Tulsa, AZ
* filtered for white or black victim races only

```{r}
# Load data
homicide = read_csv("homicide-data.csv")


# Clean data
homicide = homicide %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    solved = ifelse(disposition == "Closed by arrest", 1, 0),
    victim_sex = ifelse(victim_sex == "Unknown", NA, victim_sex),
    victim_age = as.numeric(victim_age)
  ) %>% 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL") &
    victim_race %in% c("White", "Black")
  )
```


Used `glm` to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors, then reported the adjusted odds ratio and confudence interval for solving homicides comparing male victims to female victims keeping all other variables fixed.
```{r}
# Fit logistic regression model for Baltimore, MD only
fit_baltimore = homicide %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())

baltimore_odds = fit_baltimore %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate)) %>%
  select(term, log_OR = estimate, OR, p.value) %>% 
  mutate(ci.low = exp(confint(fit_baltimore))[,1],
         ci.high = exp(confint(fit_baltimore))[,2]) 

baltimore_odds

baltimore_odds %>% 
  filter(term == "victim_sexMale") %>% 
  select(term, OR, ci.low, ci.high) %>% 
  knitr::kable(digits = 3)
```
The adjusted odds ratio for solving homicides comparing male victims to female victims holding age and race fixed is **`r baltimore_odds %>% filter(term == "victim_sexMale") %>% pull (OR) %>% round(3)` (`r baltimore_odds %>% filter(term == "victim_sexMale") %>% pull (ci.low) %>% round(3)`, `r baltimore_odds %>% filter(term == "victim_sexMale") %>% pull (ci.high) %>% round(3)`)**.

Ran glm for each of the cities in the dataset, and extracted the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. 
```{r}
city_odds = homicide %>% 
  nest(data = -city_state) %>% 
  mutate(
  glm = purrr::map(.x = data, ~glm(solved ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
  glm_tidy = purrr::map(glm, broom::tidy)
  ) %>% 
  unnest(cols = glm_tidy) %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
      OR = exp(estimate),
      ci.low = exp(estimate - 1.96*std.error),
      ci.high = exp(estimate + 1.96*std.error)
    ) %>% 
  select(city_state, OR, ci.low, ci.high)
  

city_odds %>% knitr::kable(digits = 3)
```

Below is a plot that shows the estimated ORs and CIs for each city. 

```{r}
city_odds %>% 
  mutate(
   city_state = fct_reorder(city_state, OR) 
  ) %>% 
  ggplot() +
  geom_point(aes(x = city_state, y = OR)) +
  geom_errorbar(aes(x = city_state, ymin = ci.low, ymax = ci.high)) +
  geom_hline(aes(yintercept = 1), color = "orange", lty = "dashed") +
  theme_classic() +
  labs(
    x = "City",
    y = "Odds ratio",
    title = "Odds ratio for solving homicides among male victims vs female victims",
    caption = "Adjusting for victim age (continuous) and victim race (binary: black/white)"
  ) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

* New York, NY has the lowest odds ratio of solving homicides for male victims compared to female victims, holding victim age and victim race constant. 
* Albuquerque, NM has the highest odds ratio of solving homicides for male victims compared to female victims, holding victim age and victim race constant. 
* From the plot, we can see that most cities have an odds ratio less than 1, meaning that the odds of solving homicides for male victims is lower than the odds of solving homicides for female victims for most cities, holding victim age and victim race constant. 
* Cities with higher odds ratios for solving homicides for male victims compared to female victims tend to have wider 95% confidence intervals 

* Only Nashville, TN, Fresno, CA, Stockton, CA and Albuquerque, NM have higher odds of solving homicides for male victims than female victims, holding victim age and race constant.
  * However, it is important to note that these odds ratios are not significant due to the wide range of 95% CI encompassing the null value.

# Problem 3
In this problem, I analyzed data gathered to understand the effects of several variables on a child’s birthweight. This dataset consists of roughly 4000 children and includes the following variables:

babysex: baby’s sex (male = 1, female = 2)
bhead: baby’s head circumference at birth (centimeters)
blength: baby’s length at birth (centimeteres)
bwt: baby’s birth weight (grams)
delwt: mother’s weight at delivery (pounds)
fincome: family monthly income (in hundreds, rounded)
frace: father’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other, 9 = Unknown)
gaweeks: gestational age in weeks
malform: presence of malformations that could affect weight (0 = absent, 1 = present)
menarche: mother’s age at menarche (years)
mheigth: mother’s height (inches)
momage: mother’s age at delivery (years)
mrace: mother’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other)
parity: number of live births prior to this pregnancy
pnumlbw: previous number of low birth weight babies
pnumgsa: number of prior small for gestational age babies
ppbmi: mother’s pre-pregnancy BMI
ppwt: mother’s pre-pregnancy weight (pounds)
smoken: average number of cigarettes smoked per day during pregnancy
wtgain: mother’s weight gain during pregnancy (pounds)
Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).



Loaded birthweight data and cleaned it by defining categorical variables as listed.
```{r}
bwt = read_csv("birthweight.csv")

bwt = bwt %>% 
  mutate(
    babysex = factor(babysex),
    frace = factor(frace),
    malform = factor(malform),
    mrace = factor(mrace)
  )

sum(is.na(bwt))
```
To fit my regression model for birthweight, I selected gestational weeks (gaweeks), mother's weight gain during pregnancy (wtgain), baby’s length at birth (blength) and number of live births prior (parity) because I expect these to be closely and more directly related to birthweight from a biological standpoint. I fitted the regression model and plotted a residual plot below:

```{r}
m1 = lm(bwt ~ gaweeks + wtgain + blength + parity, data = bwt)
m1

m1.df = bwt %>% 
  modelr::add_predictions(m1) %>% 
  modelr::add_residuals(m1) %>% 
  select(bwt, gaweeks, wtgain, blength, pred, resid) 

m1.df %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  labs(
    x = "Fitted (predicted) values",
    y = "Model residuals",
    title = "Model residuals against fitted values - Model 1",
    caption = "Model 1 predictors: gestational weeks,  mother's weight gain during pregnancy, baby’s length at birth"
  ) +
  theme_classic()
```

* There is no clear pattern in the plot
* Residuals seem to be randomly and symmetrically scattered around zero for the entire range of fitted values. 

All in all, this means that the residuals are normally distributed, with a mean of around zero and a constant vaariance, which fit the assumptions for fitting a linear regression model.

Next, I compared your model to two others:

One using length at birth and gestational age as predictors (main effects only) - m2
One using head circumference, length, sex, and all interactions (including the three-way interaction) between these - m3


```{r}
m2 = lm(bwt ~ blength + gaweeks, data = bwt)
m2

m3 = lm(bwt ~ bhead*blength*babysex, data = bwt)
m3
```


Then I used `crossv_mc` to obtain the cross-validated prediction error to properly compare the 3 models.
```{r}
bwt_cv = bwt %>% 
  crossv_mc(100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  mutate(m1_cv = map(train, ~lm(bwt ~ gaweeks + wtgain + blength, data = .x)),
         m2_cv = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         m3_cv = map(train, ~lm(bwt ~ bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_m1 = map2_dbl(m1_cv, test, ~rmse(model = .x, data = .y)),
         rmse_m2 = map2_dbl(m2_cv, test, ~rmse(model = .x, data = .y)), 
         rmse_m3 = map2_dbl(m3_cv, test, ~rmse(model = .x, data = .y)))

bwt_cv %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  theme_classic()
```

The prediction accuracy in my model (m1) is slightly better than that if model 2 (likely because there is overlap in the predictors), but m3 is the best-fitting model as it has the lwoest RMSE.

